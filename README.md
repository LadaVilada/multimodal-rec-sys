# multimodal-rec-sys
Multimodal Recommendation System

# Multi-modal Content Recommendation System

An experimental recommendation system that explores how to combine image, text, and video understanding for personalized content suggestions.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.10+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸš€ Overview

This project is my first exploration into building a multi-modal recommendation system. It focuses on:

- ğŸ“· Processing and understanding content across multiple modalities (images, text, videos)
- ğŸ§  Creating a shared embedding space for cross-modal similarity
- ğŸ§­ Generating content suggestions based on user queries or sample inputs
- ğŸ” Experimenting with retrieval, fusion, and hybrid recommendation techniques

---

## âš™ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/LadaVilada/multimodal-rec-sys.git
cd multimodal-rec-sys

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate

# Install required Python packages
pip install -r requirements.txt
```

---

## ğŸ§ª Getting Started

Once installed, run the system locally using sample data:

### ğŸ”„ 1. Preprocess Sample Data

```bash
python -m scripts.preprocess --dataset sample
```

### ğŸ§  2. Train a Model

```bash
python -m scripts.train --config configs/sample.yaml
```

### ğŸŒ 3. Start the API (FastAPI backend)

```bash
python -m api.main
# or using uvicorn
uvicorn api.main:app --reload
```
## ğŸ“˜ API Documentation (Swagger)

Once the FastAPI server is running, you can explore and test the available endpoints using the auto-generated Swagger UI:

ğŸ“ [http://localhost:8000/docs](http://localhost:8000/docs)  
ğŸ“ [http://localhost:8000/redoc](http://localhost:8000/redoc)

These interfaces provide a visual way to interact with the API, send requests, and view responses in real time.

You can also use tools like Postman or curl to interact with the API endpoints directly.
Visit: [http://localhost:8000/docs](http://localhost:8000/docs)

### ğŸ’» 4. Start the Frontend (React)

```bash
cd frontend
npm install
npm start
```

Visit: [http://localhost:3000](http://localhost:3000)

---

## ğŸ§  Project Structure

```
MultiModal-RecSys/
â”œâ”€â”€ data/              # Preprocessing scripts and sample data
â”œâ”€â”€ models/            # Encoders, fusion logic, and recommendation engines
â”œâ”€â”€ api/               # FastAPI backend
â”œâ”€â”€ scripts/           # Training and evaluation scripts
â”œâ”€â”€ frontend/          # React interface
â”œâ”€â”€ notebooks/         # Experiments and visualizations
â”œâ”€â”€ tests/             # Unit and integration tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

